{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0599e97",
   "metadata": {},
   "source": [
    "> # CutMix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd3de5",
   "metadata": {},
   "source": [
    "The Deep ConvNets show great performance on various computer vision tasks such as classification, object detection, semantic segmentation, and video analysis. For these tasks, many **data augmentation** and **regularization** techniques have been proposed to increase performance.\n",
    "\n",
    "In particular, to prevent overfitting, co-adaptation, and excessively relying on the small portion of intermediate activations or small region on input images, **random feature removal regularization** techniques have been proposed including **dropout** and **regional dropout** which erases random spatial regions on the input image. The empirical studies showed that these regularization methods do show improved generalization and localization.\n",
    "\n",
    "Yet, the author suggests that such techniques in fact **greatly reduce the proportion of informative pixels on trainig images** which is considered as a **severe conceptual limitation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09252d81",
   "metadata": {},
   "source": [
    "> # What is the paper trying to address?\n",
    "\n",
    "The paper is asking **how to maximally utilize the deleted regions while preserving generalization and localization effects using regional dropout?**\n",
    "\n",
    "The above question is addressed by an data augmentation method called **CutMix** which **replaces the deleted regions with a path from another image**. Then what about the labels? The **ground truth labels are also mixed proportionally to the number of pixels of the combined two images**.\n",
    "\n",
    "Consequently, utilizing the deleted(replaced) regions, there's no information loss during training like plain regional dropout. Another effect of CutMix is that it enhances the localization ability because the replacement of a patch requires the learner to identify the object from a **partial view**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5874d92",
   "metadata": {},
   "source": [
    "| ![cutmix](../images/cutmix1.png) | \n",
    "|:--:| \n",
    "| *[cutmix](https://arxiv.org/pdf/1905.04899.pdf)* |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e0fca",
   "metadata": {},
   "source": [
    "CuxMix shows similarity with Mixup as they both mix two images by interpolating both the image and the label. However, Mixup samples are more \"unnatural\" as you can see the co-presence of dog and cat(I personally think CutMix samples look weird too..). Although Mixup and Cutout give better performance, they don't do really well for ImageNet classification and object detection tasks. Meanwhile, CutMix shows improved performance for all the tasks.\n",
    "\n",
    "* CutMix is applied to a baseline classifier on CIFAR-10 and achieved $14.47\\%$ top-1 error. Also, ResNet-50 and ResNet-101 show $+2.28\\%$ and $1.70\\%$ classification accuracy improvements with CutMix.\n",
    "* Cutmix also enhances the performnace of weakly-supervised object localization(WOL) task.\n",
    "* CutMix achieves $+1 mAP$ increased performance on detection for Pascal VOC and $+2 BLEU$ scoresfor image captioning performance on MS-COCO dataset.\n",
    "* Lastly, CutMix enhances the **model robustness** and alleviates the **over-confidence** issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d168e0cf",
   "metadata": {},
   "source": [
    "> # Comparison with other techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f22330",
   "metadata": {},
   "source": [
    "> ## Regional Dropout\n",
    "\n",
    "Regional dropouts remove random regions in images and indeed show better generalization performance. While CutMix is similar to regional dropout, the key difference is that CutMix **remove and replace** with a patch from another image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8b0c45",
   "metadata": {},
   "source": [
    "> ## Synthesizing training data\n",
    "\n",
    "A synthesizing technique such as **Stylizing ImageNet** suggests to focus more on shape than texture. Unlike this technique, CutMix requires only **trivial additional cost for training** while generating new samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8964a760",
   "metadata": {},
   "source": [
    "> ## Mixup\n",
    "\n",
    "Mixup samples sometimes confuse the model by introducing locally ambiguous and unnatural images. Some other variants of Mixu perform feature-level interpolation but they lack localization ability and transfer-learning performance. On the other hand, CutMix enjoys performance boost for classification, localization, and transfer learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e002f4",
   "metadata": {},
   "source": [
    "> ## Complementary to other methods\n",
    "\n",
    "CutMix goes well along with **weight decay**, **batch normalization**, and **adding noises**. CutMix can be complementary to those methods since CutMix only operates on **data level**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5faf7879",
   "metadata": {},
   "source": [
    "> # CutMix Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8f6af5",
   "metadata": {},
   "source": [
    "## Notations\n",
    "* $x \\in \\mathbb{R}^{W*H*C}$: training image\n",
    "* $y$: label\n",
    "* $(x_A,y_A)$, $(x_B,y_B)$: training samples before CutMix\n",
    "* $(\\tilde{x},\\tilde{y})$: New training sample after CutMix\n",
    "\n",
    "\n",
    "## CutMix Operation\n",
    "$$\\tilde{x}=M \\odot x_A + (1-M) \\odot x_B$$\n",
    "$$\\tilde{y}=\\lambda y_A + (1-\\lambda)y_B$$\n",
    "\n",
    "where\n",
    "* $M \\in {0,1}^{\\{W*H\\}}$ denotes a **binary mask** indicating **where to drop out** and **fill in** from two images.\n",
    "* $1$ is a binary mask filled with **ones**.\n",
    "* $\\odot$ is element-wise multiplication.\n",
    "* $\\lambda$ is the **combination ratio** between two data and is sampled from the **uniform distribution** $U(0,1)$.\n",
    "* The binary mask $M$ is obtained by sampling the bounding box coordinates $B = (r_x,r_y,r_w,r_h)$ referring to the cropped regions on $x_A$ and $x_B$. The region $B$ in $x_A$ is **removed** and **replaced** with the other patch cropped from $B$ of $x_B$.\n",
    "* For $r_x, r_y, r_w, r_h$,\n",
    "$$r_x \\sim U(0,W),\\ r_w = W\\sqrt{1-\\lambda}$$    \n",
    "$$r_y \\sim U(0,H),\\ r_h = H\\sqrt{1-\\lambda}$$\n",
    "\n",
    "     making the cropped area ratio $\\frac{r_wr_h}{WH}=1-\\lambda$.\n",
    "* From the cropped region, the binary mask $M \\in {\\{0,1\\}^{W*H}}$ is filled with $0$ within the bounding box $B$, $0$ otherwise.\n",
    "\n",
    "In each training iteration, $(\\tilde{x},\\tilde{y})$ is generated by combining **randomly selected two samples in a mini-batch** by equations (2) and (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77e827b",
   "metadata": {},
   "source": [
    "> # CutMix on Class Activation Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030609c6",
   "metadata": {},
   "source": [
    "| ![cutmix](../images/cutmix2.png) | \n",
    "|:--:| \n",
    "| *[cutmix](https://arxiv.org/pdf/1905.04899.pdf)* |\n",
    "\n",
    "| ![cutmix](../images/cutmix3.png) | \n",
    "|:--:| \n",
    "| *[CutMix](https://arxiv.org/pdf/1905.04899.pdf)* |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eff79b7",
   "metadata": {},
   "source": [
    "The above is the class activation map for Mixup, Cutout, and CutMix. For fair comparison, the vanilla **ResNet-50** model is used.\n",
    "\n",
    "While Cutout focuses on less discriminative parts such as belly, it loses informative pixel values. Mixup fully uses the pixels, it introduces unnatural artifacts and confuses the model which object to choose. The author hypothesizes that this confusion results in suboptimal performance on classification and localization.\n",
    "\n",
    "On the other hand, CutMix successfully localize the two object classes as demonstrated in the above figure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79171d9",
   "metadata": {},
   "source": [
    "> # Validation Error\n",
    "\n",
    "* **ResNet-50** is used for ImageNet Classification\n",
    "* **PyramidNet-200** is used for CIFAR-100 Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5762ae1e",
   "metadata": {},
   "source": [
    "| ![cutmix](../images/cutmix4.png) | \n",
    "|:--:| \n",
    "| *[CutMix](https://arxiv.org/pdf/1905.04899.pdf)* |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565fb8f3",
   "metadata": {},
   "source": [
    "The graph shows that applying CutMix results in **lower validation error** at the end of the training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debe760f",
   "metadata": {},
   "source": [
    "> # Comparison with other methods for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be2c507",
   "metadata": {},
   "source": [
    "For fair comparision, the standard data augmentation setting such as resizing, cropping, and flipping. The time to reach convergence for CutMix requires a higher number of training epochs.\n",
    "\n",
    "### ImageNet\n",
    "All the models were trained with 300 epochs with lr=0.1, lr decay 0.1 at epochs 75,150,225, batch size=256, $\\alpha=1$.\n",
    "\n",
    "### CIFAR-10\n",
    "Mini-batch size of 64, 300 epochs, 0.25 learning rate, decay rate 0.1 at 150 and 225 epochs.\n",
    "\n",
    "| ![cutmix](../images/cutmix5.png) | \n",
    "|:--:| \n",
    "| *[CutMix](https://arxiv.org/pdf/1905.04899.pdf)* |\n",
    "\n",
    "| ![cutmix](../images/cutmix7.png) | \n",
    "|:--:| \n",
    "| *[CutMix](https://arxiv.org/pdf/1905.04899.pdf)* |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f72f078",
   "metadata": {},
   "source": [
    "> ## vs Architectural Improvements\n",
    "\n",
    "CutMix imporves the performance by $+2.28\\%$ while increased depth from **ResNet-50** to **ResNet-152** increases $+1.99\\%$. Along with better performance gain, CutMix requires much less memory or computational cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723ec41d",
   "metadata": {},
   "source": [
    "> # CutMix Pseudo-code\n",
    "\n",
    "| ![cutmix](../images/cutmix9.png) | \n",
    "|:--:| \n",
    "| *[CutMix](https://arxiv.org/pdf/1905.04899.pdf)* |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7dd8b3",
   "metadata": {},
   "source": [
    "> # Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8e05a3",
   "metadata": {},
   "source": [
    "**CutMix** consistenly improves performance on image classification, localization, semantic segmentation, and object detection. Also, using CutMix-ImageNet pretrained model as the initialized backbone of the object detection and image captionining brings performance improvements as well. For ImageNet, ResNet-50 and ResNet-101 with CutMix show $+2.28\\%$ and $+1.70\\%$ top-1 accuracy. For CIFAR-10, CutMix significantly improves the baseline architectures such as **PyramidNet-110** and **ResNet-110**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
